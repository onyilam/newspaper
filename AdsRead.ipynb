{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#encoding=utf-8\n",
    "import sys, codecs, re, os, csv\n",
    "from io import open\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "\n",
    "pd.options.display.max_rows = 9999999\n",
    "path = os.getcwd()  \n",
    "AppleDir = os.path.join(path,\"AppleAds\")\n",
    "OriDir = os.path.join(path,\"OriAds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/onyi/Dropbox/newspaper/advertisement/AppleAds'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AppleDir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Reading the Advertisement</h4>\n",
    "The ads are stored as txt files with a few structure. I parse the txt file to retrive relvenat information (company name, product name, date...etc), and then convert them into dataframe for analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OriIndList = {}\n",
    "OriComp ={}\n",
    "OriAd={}\n",
    "OriCompiled=DataFrame()\n",
    " \n",
    "\n",
    "#Read Advertisement at Orietal Daily\n",
    "for dir_entry in os.listdir(OriDir):\n",
    "    if not dir_entry.startswith('.'):\n",
    "        dir_entry_path = os.path.join(OriDir, dir_entry)\n",
    "        if os.path.isfile(dir_entry_path):\n",
    "            try: \n",
    "                with open(dir_entry_path) as f: \n",
    "                    RawOriInd = f.read()\n",
    "                    OriIndList[dir_entry] = re.split(r': Wisers electronic service. This content, the trademarks and logos belong to Wisers, the relevant organizations or copyright owners. All rights reserved. Any content provided by user is the responsibility of the user and Wisers is not responsible for such content, copyright clearance or any damage/loss suffered as a result.', RawOriInd)\n",
    "                    OriIndList[dir_entry] = [ re.sub(r'\\n', ' ', ad) for ad in OriIndList[dir_entry]]\n",
    "                    OriIndList[dir_entry] = [ re.sub(r'--', ' ', ad) for ad in OriIndList[dir_entry]]\n",
    "                    OriIndList[dir_entry] = [ re.sub(r'\\s+', ' ', ad) for ad in OriIndList[dir_entry]]\n",
    "                    OriIndList[dir_entry] = [ re.sub(r'- Source|Newspaper', ' ', ad) for ad in OriIndList[dir_entry]]\n",
    "                    OriIndList[dir_entry] = [ re.split(r'廣告:|Product Category:| \\| | DOCUMENT ID: | Brand:' , ad) for ad in OriIndList[dir_entry] ]      \n",
    "                    OriAd[dir_entry] = DataFrame(OriIndList[dir_entry])\n",
    "                    OriAd[dir_entry]= OriAd[dir_entry].ix[:,0:8]\n",
    "                    OriAd[dir_entry].columns = [ 'newspaper','date','position','x','x2','ad','industries','Company','ID']\n",
    "                    OriAd[dir_entry]['Company'] = OriAd[dir_entry]['Company'].str.split('Product:').apply(Series, 1)[0]\n",
    "                    ind = re.sub(r\".txt\", '', dir_entry)\n",
    "                    ind_name=ind[7:]\n",
    "                    OriAd[dir_entry]['industry'] = ind_name\n",
    "                    OriAd[dir_entry] = OriAd[dir_entry][OriAd[dir_entry].Company.str.contains(\"東方日報\") == False ]\n",
    "                    \n",
    "                \n",
    "                    #spliting the companies into rows\n",
    "                    s = OriAd[dir_entry]['Company'].str.split(',').apply(Series, 1).stack()\n",
    "                    s.index = s.index.droplevel(-1)\n",
    "                    s.name = 'Company'\n",
    "                    del OriAd[dir_entry]['Company']\n",
    "                    OriAd[dir_entry]=OriAd[dir_entry].join(s)\n",
    "                    \n",
    "                    #Discard NaN rows\n",
    "                    OriAd[dir_entry] = OriAd[dir_entry][pd.notnull(OriAd[dir_entry].Company)] #remove entries with nan company\n",
    "                    #Discard companies == ltd.\n",
    "                    OriAd[dir_entry] = OriAd[dir_entry][OriAd[dir_entry].Company != 'Ltd.' ]\n",
    "                    OriAd[dir_entry] = OriAd[dir_entry][OriAd[dir_entry].Company != 'ltd.' ]\n",
    "                    \n",
    "                    \n",
    "                    #write the dataframe into CSV file\n",
    "                    name = re.sub(r\".txt\", '', dir_entry)+'df.csv'\n",
    "                    OriDirDf = OriDir+'/Df'\n",
    "                    OriAd[dir_entry].to_csv(os.path.join(OriDirDf, name))\n",
    "                        \n",
    "            except UnicodeDecodeError as e: \n",
    "                    print(\"Some error occurred decoding file %s: %s\" % (dir_entry, e)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "AppleIndList = {}\n",
    "ApAd = {}\n",
    "ApCompiled=DataFrame()\n",
    "ApComp = {}\n",
    "\n",
    "#Read Advertisement at Apple Daily\n",
    "for dir_entry in os.listdir(AppleDir):\n",
    "    if not dir_entry.startswith('.'):\n",
    "        dir_entry_path = os.path.join(AppleDir, dir_entry)\n",
    "        if os.path.isfile(dir_entry_path):\n",
    "            try: \n",
    "                with open(dir_entry_path) as f: \n",
    "                    RawApInd = f.read()\n",
    "                    AppleIndList[dir_entry] = re.split(r': Wisers electronic service. This content, the trademarks and logos belong to Wisers, the relevant organizations or copyright owners. All rights reserved. Any content provided by user is the responsibility of the user and Wisers is not responsible for such content, copyright clearance or any damage/loss suffered as a result.', RawApInd)\n",
    "                    AppleIndList[dir_entry] = [ re.sub(r'\\n', ' ', ad) for ad in AppleIndList[dir_entry]]\n",
    "                    AppleIndList[dir_entry] = [ re.sub(r'--', ' ', ad) for ad in AppleIndList[dir_entry]]\n",
    "                    AppleIndList[dir_entry] = [ re.sub(r'\\s+', ' ', ad) for ad in AppleIndList[dir_entry]]\n",
    "                    AppleIndList[dir_entry] = [ re.sub(r'- Source|Newspaper', ' ', ad) for ad in AppleIndList[dir_entry]]\n",
    "                    AppleIndList[dir_entry] = [ re.split(r'廣告:|Product Category:| \\| | DOCUMENT ID: | Brand:' , ad) for ad in AppleIndList[dir_entry] ]\n",
    " \n",
    "                    ApAd[dir_entry] = DataFrame(AppleIndList[dir_entry])\n",
    "                    ApAd[dir_entry]= ApAd[dir_entry].ix[:,0:8]\n",
    "                    ApAd[dir_entry].columns = ['newspaper', 'date','position','x','x2','ad','industries','Company','ID']\n",
    "                    ApAd[dir_entry]['Company'] = ApAd[dir_entry]['Company'].str.split('Product:').apply(Series, 1)[0]\n",
    "                    ind = re.sub(r\".txt\", '', dir_entry)\n",
    "                    ind_name=ind[9:]\n",
    "                    ApAd[dir_entry]['industry'] = ind_name  \n",
    "                    \n",
    "                    ApAd[dir_entry] = ApAd[dir_entry][ApAd[dir_entry].Company.str.contains(\"蘋果日報\") == False ]\n",
    "                \n",
    "                    #spliting the companies into rows\n",
    "                    s = ApAd[dir_entry]['Company'].str.split(',').apply(Series, 1).stack()\n",
    "                    s.index = s.index.droplevel(-1)\n",
    "                    s.name = 'Company'\n",
    "                    del ApAd[dir_entry]['Company']\n",
    "                    ApAd[dir_entry]=ApAd[dir_entry].join(s)\n",
    "                    \n",
    "                    #Discard NaN rows\n",
    "                    ApAd[dir_entry] = ApAd[dir_entry][pd.notnull(ApAd[dir_entry].Company)] #remove entries with nan company\n",
    "                   \n",
    "                    #Discard companies == ltd.\n",
    "                    ApAd[dir_entry] = ApAd[dir_entry][ApAd[dir_entry].Company != 'Ltd.' ]\n",
    "                    ApAd[dir_entry] = ApAd[dir_entry][ApAd[dir_entry].Company != 'ltd.' ]\n",
    "     \n",
    "                    #write the dataframe into CSV file\n",
    "                    name = re.sub(r\".txt\", '', dir_entry)+'df.csv'\n",
    "                    ApDirDf = AppleDir+'/Df'\n",
    "                    ApAd[dir_entry].to_csv(os.path.join(ApDirDf, name))\n",
    "                    \n",
    "                    \n",
    "                    \n",
    "            except UnicodeDecodeError as e: \n",
    "                    print(\"Some error occurred decoding file %s: %s\" % (dir_entry, e)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> Getting a list of Unique Companies </h4>\n",
    "I need to get a list of unique companies to determine the company charcaterisitcs (foreign vs local, politically connected or not)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# sort by company names\n",
    "OriComp=OriCompiled['companies'].value_counts().sort_index()\n",
    "ApComp = ApCompiled['companies'].value_counts().sort_index()\n",
    "\n",
    "#append all companies together and export to csv\n",
    "writer = csv.writer(open('OriCompList.csv', 'wt'),  delimiter=',')\n",
    "for value in OriComp.items():\n",
    "    writer.writerow([value])\n",
    "\n",
    "writer = csv.writer(open('ApCompList.csv', 'wt'))\n",
    "for value in ApComp.items():\n",
    "    writer.writerow([value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#read csv file of all the companies\n",
    "with open('AllCompanies.csv', 'rt') as f:\n",
    "    reader = csv.reader(f)\n",
    "    CompaniesList = list(reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#flatten the list of list to list\n",
    "import functools\n",
    "CompList=functools.reduce(lambda x,y: x+y,CompaniesList)\n",
    "\n",
    "#remove the products in the companaies \n",
    "for index, item in enumerate(CompList):\n",
    "    \n",
    "    found=re.search('(.+?)Product:', item)\n",
    "    if found is not None:\n",
    "        found=re.search('(.+?) Product:', item).group(1)\n",
    "        CompList[index] = found\n",
    "    #if len(found)>0:\n",
    "    #re.sub(r'(.+?)Product:(.+?)', found, )\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#function to retrieve unique values in a list\n",
    "def UniqueVal(seq, idfun=None): \n",
    "    # order preserving\n",
    "    if idfun is None:\n",
    "        def idfun(x): return x\n",
    "   \n",
    "    seen = {}\n",
    "    result = []\n",
    "    for item in seq:\n",
    "        marker = idfun(item)\n",
    "        if marker in seen: continue\n",
    "        seen[marker] = 1\n",
    "        result.append(item)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "UniqComp=UniqueVal(CompList)\n",
    "\n",
    "writer = csv.writer(open('UniqCompList.csv', 'wt'),  delimiter=',')\n",
    "for value in UniqComp:\n",
    "    writer.writerow([value])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
